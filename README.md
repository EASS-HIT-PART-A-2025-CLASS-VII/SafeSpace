# SafeSpace - AI-Powered Mental Health Companion

A sophisticated mental health companion app built with modern microservices architecture, featuring AI-powered mood analysis, personalized playlist generation, and therapeutic activities.

![The name is SafeSpace, it a mental health app, and theme color is baby yellow](https://github.com/user-attachments/assets/8bcfd4e9-106b-400a-b7ef-24a3e3349224)


## ğŸ—ï¸ Architecture

### Modern Microservices Design
- **Frontend**: React + TypeScript + Vite + Tailwind CSS
- **Backend API**: FastAPI + Pydantic for request validation
- **LLM Microservice**: Ollama (Gemma 2B) for AI-powered features
- **Containerization**: Docker + Docker Compose for easy deployment

### Key Features
- ğŸ§  **AI-Powered Mood Analysis**: Intelligent mood detection and personalized suggestions
- ğŸµ **AI Music Generation**: Ollama-curated playlists based on emotional state
- ğŸ’­ **AI Affirmations**: Personalized supportive messages generated by local LLM
- ğŸ« **Breathing Exercises**: Guided breathing with mood-specific patterns
- ğŸ“ **Journaling Space**: Therapeutic writing with AI-powered prompts
- ğŸ® **Grounding Games**: Interactive activities for anxiety and stress
- âœ¨ **Joy Jar**: Capture and revisit happy moments
- ğŸ§ **Audio Therapy**: Curated soundscapes for different moods

## ğŸ¥ Demo
youtube link

![image](https://github.com/user-attachments/assets/4eaf75cc-e176-4128-add8-9d0a8182431c)

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- At least 4GB RAM (for Ollama LLM)

### One-Click Setup
1. Clone the repository
2. Start the entire application:
   ```bash
   docker-compose up --build
   ```

### Access Points
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **LLM Service**: http://localhost:8080
- **API Documentation**: http://localhost:8000/docs

## ğŸ¤– AI Integration

### Local LLM with Ollama
- **Model**: Gemma 2B (lightweight, fast, privacy-focused)
- **Features**: 
  - Intelligent playlist generation with real song recommendations
  - Personalized affirmations based on mood and intensity
  - Mood analysis and activity suggestions
- **Privacy**: All AI processing happens locally - no data sent to external services

### API Integration
The LLM service seamlessly integrates with the main backend to provide:
- Enhanced user experience through personalization
- Intelligent content generation
- Adaptive responses based on user emotional state

## ğŸ›¡ï¸ Safety & Privacy

- **Non-Clinical Approach**: Supportive companion, not medical advice
- **Crisis Detection**: Automatic referral to professional resources
- **Local Processing**: All AI happens on your machine
- **No Authentication**: Simple, free-run app for easy access

## ğŸ¯ Technical Highlights

### Modern Software Engineering
- **Microservices Architecture**: Scalable, maintainable service separation
- **API-First Design**: RESTful APIs with OpenAPI documentation
- **Containerization**: Docker for consistent deployment
- **Type Safety**: TypeScript frontend, Pydantic backend validation
- **Local AI**: Ollama integration for privacy-focused AI features

### Production Ready
- **Health Checks**: Service monitoring and status endpoints
- **Error Handling**: Graceful degradation and fallback systems
- **CORS Configuration**: Secure cross-origin resource sharing
- **Environment Management**: Configurable for different deployment stages

## ğŸ“Š Use Cases

### For Users
- Daily mood check-ins with AI-powered support
- Anxiety management through breathing and grounding exercises
- Depression support via journaling and affirmations
- Stress relief through AI-curated audio experiences
- Emotional growth tracking and pattern recognition

### For Developers
- Modern full-stack architecture example
- Microservices implementation
- Local AI/LLM integration patterns
- Docker containerization best practices
- FastAPI + React integration

## ğŸŒŸ Innovation

This project showcases cutting-edge software engineering practices:
- **Product Engineering Approach**: User-centric design with technical excellence
- **Local AI-First Features**: Privacy-focused LLM integration with Ollama
- **Microservices Architecture**: Scalable, maintainable system design
- **Modern Tech Stack**: Latest frameworks and best practices
- **Real-World Application**: Addresses genuine mental health needs

## ğŸ”§ Development

### Local Development
```bash
# Frontend
npm install
npm run dev

# Backend
cd backend
pip install -r requirements.txt
uvicorn main:app --reload

# LLM Service (requires Ollama installed)
cd llm-service
pip install -r requirements.txt
uvicorn main:app --port 8080 --reload
```

### Project Structure
```
safespace/
â”œâ”€â”€ frontend/               # React frontend
â”œâ”€â”€ backend/                # FastAPI backend
â”œâ”€â”€ llm-service/            # Ollama AI microservice
â”œâ”€â”€ docker-compose.yml      # Container orchestration
â””â”€â”€ README.md
```

## ğŸ“ˆ Future Enhancements

- **Mobile App**: React Native companion
- **Advanced AI**: Fine-tuned models for mental health
- **Offline Mode**: Complete offline functionality
- **Voice Integration**: Speech-to-text mood input
- **Analytics Dashboard**: Personal insights and trends

---

Built with â¤ï¸ for mental health awareness and modern software engineering excellence.

**Note**: This is a school project designed to run locally using Docker. No external services or complicated setup required - just Docker and you're ready to go!
